{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Preprocessing Execise.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPlhhzS32qs9I3VjGP1O37P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing Exercise:**\n",
        "The following exercise show how raw data is prepared(preprocessed) for analysis can be done. The data includes numeric data, categorical data and missing data in the numeric columns. The steps are as follows:\n"
      ],
      "metadata": {
        "id": "p9YNYUgk47if"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import the pandas and numpy libraries"
      ],
      "metadata": {
        "id": "Oylbn_4U6emP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_BHc0-s22pxz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import the dataset and slice it into two: dependent and independent variables. For the independent variables we will select the country, age and salary columns. For the dependent variable we will select the purchase column.\n"
      ],
      "metadata": {
        "id": "qOvWH_pO6miJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data = pd.read_csv('Raw_Data.csv')\n",
        "x = Data.iloc[:,:-1].values\n",
        "y = Data.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "2K5D5eRy4XxC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print x and y to confirm the selected variables"
      ],
      "metadata": {
        "id": "U7p4fmgC6mg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJgYYx5E7zsf",
        "outputId": "42c5ce21-8757-44c8-e581-832c448b222e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2b1IT9J71xF",
        "outputId": "8341458a-6acd-4a5c-8d4b-d82b3fda551b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Take care of missing values in the age and salary columns. I will replace the missing values with the mean of each column."
      ],
      "metadata": {
        "id": "6vQ5aFyj9YT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(x[:,1:3])\n",
        "x[:,1:3] = imputer.transform(x[:,1:3])"
      ],
      "metadata": {
        "id": "MEdtZMP297GM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmwIL2tAEtIl",
        "outputId": "12985ae9-001e-4620-cb38-a62685af0d03"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Take care of categorical data in the country and purchase columns. I will use the onehotencoder library for the purchase column and use the labelencoder library for the purchase column."
      ],
      "metadata": {
        "id": "qejDYuPEFNeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "zhG0xrVFGgcH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61O5O4lEI75u",
        "outputId": "585b9c39-b9b8-4529-e11f-1d618c75a8b2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "UiA04T1CJAOq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdzkc8LlJNjI",
        "outputId": "94357aea-a3de-40a4-8603-8346f3865ebc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Split the data into training set and test set."
      ],
      "metadata": {
        "id": "HEBoQtZpUcrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "J-lt7j4EVBQu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHoJozT5V44L",
        "outputId": "8852e82b-9cf1-4eca-92c5-17498929d33a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 37.0 67000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZsyHqgBV5NY",
        "outputId": "0beeaf00-214d-485e-8183-1ade54f793eb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK3wOCNKV5d6",
        "outputId": "90286ef7-c89b-4206-a5b6-25a842a9a002"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af7gZpT9V5qo",
        "outputId": "c506ff3e-7665-4dd0-d9fb-1a14ab1a4bfd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Scale the data using standardization "
      ],
      "metadata": {
        "id": "TK1_s-g6WL8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "se = StandardScaler()\n",
        "x_train[:,3:] = se.fit_transform(x_train[:,3:])\n",
        "x_test[:,3:] = se.transform(x_test[:,3:])"
      ],
      "metadata": {
        "id": "vxl9unZ4WaBh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVNSu1eXZZPR",
        "outputId": "4be7a854-7ce4-4bab-ce11-d6fc95d1feee"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 0.2630675731713538 0.1238147854838185]\n",
            " [1.0 0.0 0.0 -0.25350147960148617 0.4617563176278856]\n",
            " [0.0 0.0 1.0 -1.9753983221776195 -1.5309334063940294]\n",
            " [0.0 0.0 1.0 0.05261351463427101 -1.1114197802841526]\n",
            " [1.0 0.0 0.0 1.6405850472322605 1.7202971959575162]\n",
            " [0.0 0.0 1.0 -0.08131179534387283 -0.16751412153692966]\n",
            " [1.0 0.0 0.0 0.9518263102018072 0.9861483502652316]\n",
            " [1.0 0.0 0.0 -0.5978808481167128 -0.48214934111933727]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeojpFgLZbw4",
        "outputId": "18ce93ac-45a3-460c-d1bd-e4e10f75a053"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4588292694047795 -0.9016629672292141]\n",
            " [0.0 1.0 0.0 1.984964415747487 2.139810822067393]]\n"
          ]
        }
      ]
    }
  ]
}